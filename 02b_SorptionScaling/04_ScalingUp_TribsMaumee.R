# JMH Jan 2022
# Assuming colloid-P:DRP = 0, 
# combines water quality data for three tributaries and Maumee River and estimates: 
# (1) quantity of P sorption between tributary gaging station and Waterville, OH (Fig 2) 
# and (2) the P sorption upstream of Waterville, OH (Fig. 3). 
# Conducts bootstrapping for each tributary and Maumee River and exports the bootstrap results to a csv.

# Libraries ----
library(tidyverse)
library(zoo)
library(lubridate)
library(dataRetrieval)

# Get data ----
## water quality & Q ----
  # for target stream and downstream
  # generated by code starting in 02
  StartStumpf <- as.POSIXct("2019-03-01", format = "%Y-%m-%d")
  EndStumpf <- as.POSIXct("2019-07-01", format = "%Y-%m-%d")
  
  wqUTLC <- read.csv("04a_generatedDataOnGit/02d_UTLC.csv")[,-1] %>% 
    mutate(dateTime = as.POSIXct(dateTime, format = "%Y-%m-%d %H:%M:%S"),
           Yf = as.factor(as.character(strftime(dateTime, format = "%Y"))), 
           gTarPerFlow = as.factor(gTarPerFlow)) %>% 
    filter(Yf == 2019) %>% 
    # some conversions, units are in parameter names
    mutate(Qm3m = Qm3s_utlc*60, #Q in m3/min
           SSgDMm3 = SS_mgLp*1000/1000,
           DRPgPm3 = SRP_mgLp*1000/1000) %>% 
    select(dateTime, Qm3m, SSgDMm3, DRPgPm3, gTarPerFlow) %>% 
    # filling in 1 missing data point
    mutate(Qm3m = na.approx(Qm3m),
           SSgDMm3 = na.approx(SSgDMm3),
           DRPgPm3 = na.approx(DRPgPm3),
           gTarPerFlow = ifelse(Qm3m >= 2.29*1.69901, "Gtarget", "Ltarget")) 
  
  wqWC <- read.csv("04a_generatedDataOnGit/02f_West.csv")[,-1] %>% 
    mutate(dateTime = as.POSIXct(dateTime, format = "%Y-%m-%d %H:%M:%S"),
           Yf = as.factor(as.character(strftime(dateTime, format = "%Y"))),
           gTarPerFlow = as.factor(gTarPerFlow)) %>% 
    filter(Yf == 2019) %>% 
    mutate(Qm3m = Qm3s_West*60, #Q in m3/min
           SSgDMm3 = SS_mgLp*1000/1000,
           DRPgPm3 = SRP_mgLp*1000/1000) %>% 
    select(dateTime, Qm3m, SSgDMm3, DRPgPm3, gTarPerFlow)%>% 
    # filling in 43 missing data points
    # these are distributed throughout this dataset with 15-min intervals
    mutate(Qm3m = na.approx(Qm3m),
           SSgDMm3 = na.approx(SSgDMm3),
           DRPgPm3 = na.approx(DRPgPm3),
           gTarPerFlow = ifelse(Qm3m >= 20.2*1.69901, "Gtarget", "Ltarget")) 
  
  wqSTF <- read.csv("04a_generatedDataOnGit/02f_Turk.csv")[,-1] %>% 
    mutate(dateTime = as.POSIXct(dateTime, format = "%Y-%m-%d %H:%M:%S"),
           Yf = as.factor(as.character(strftime(dateTime, format = "%Y"))),
           gTarPerFlow = as.factor(gTarPerFlow)) %>% 
    filter(Yf == 2019) %>% 
    # some conversions, units are in parameter names
    mutate(Qm3m = Qm3s_Turk*60, #Q in m3/min
           SSgDMm3 = SS_mgLp*1000/1000,
           DRPgPm3 = SRP_mgLp*1000/1000)%>% 
    select(dateTime, Qm3m, SSgDMm3, DRPgPm3, gTarPerFlow)%>% 
    # filling in 43 missing data points
    mutate(Qm3m = na.approx(Qm3m),
           SSgDMm3 = na.approx(SSgDMm3),
           DRPgPm3 = na.approx(DRPgPm3),
           gTarPerFlow = ifelse(Qm3m >= 131*1.69901, "Gtarget", "Ltarget")) 
  

  # Maumee @ waterville Q
    ## sub daily (hourly) ----
    # THIS STARTS IN 1987
    # USGS hydro network linked data index
    # https://waterdata.usgs.gov/blog/nldi-intro/
    # Little function for getting Q data I need
    StreamQGrabFun <- function(siteNo, pCode, start.date, end.date){
      Qdat<- readNWISuv(siteNumbers = siteNo,
                        parameterCd = pCode,
                        startDate = start.date,
                        endDate = end.date,
                        tz = "America/New_York")
      Qdat <-  renameNWISColumns(Qdat)
      Qdat
    }
    
    # blank time series with 15 min intervals
    library(lubridate)
    ts15minBk <- data.frame(dateTime = seq(as.POSIXct("2019-01-01", format = "%Y-%m-%d", tz = "America/New_York"),
                                as.POSIXct("2019-08-01", format = "%Y-%m-%d", tz = "America/New_York"),
                                by = "15 min"))
  
    # Maumee River near Defiance
    qMrDef <- StreamQGrabFun(siteNo = "04192500",
                             pCode = "00060",
                             start.date = "2019-01-01",
                             end.date = "2019-08-01") %>% 
            mutate(dateTime = as.POSIXct(dateTime, format = "%Y-%m-%d %H:%M:%S", tz = "America/New_York")) %>% 
            mutate(Qm3m_MrDef = Flow_Inst/35.3*60) %>% # convert from cfs to m3m
            select(dateTime, Qm3m_MrDef)%>% 
            # join with 15 min time series
            full_join(ts15minBk, by = "dateTime") %>% 
            # sort by date
            arrange(dateTime) %>% 
            # interpolate blanks
            mutate(Qm3m_MrDef = na.approx(Qm3m_MrDef))
    
    # Maumee River at Waterville for Maumee scaling
    wqMaum <- read.csv("04a_generatedDataOnGit/02d_MaumeeWatervilleWaterQual.csv", row.names = 1) %>% 
              mutate(Date = as.POSIXct(Date, format = "%Y-%m-%d", tz = "America/New_York"),
                     SmpTimeWindowDay = 1) #daily data so window in days -=1


## reach slope & length ----
  # cleaned by 03_CleanSegSlopes
segInfo <- read.csv("04a_generatedDataOnGit/03d_slopes.csv")

## sorption data ----
  # generated by 01_SorpDataMungeFigS4_S5
  SorpHF <- read.csv("04a_generatedDataOnGit/04d_SorpDat.csv", row.names =1) %>% 
    filter(Percentile_flow >= 75)
  
  SorpWC_Hf <- SorpHF %>% 
                filter(Stream == "WC")
  SorpSTF_Hf <- SorpHF %>% 
                filter(Stream == "STF")
  SorpUTLC_Hf <- SorpHF %>% 
                filter(Stream == "UTLC")


## Watershed areas ----
    gsWA <- read.csv("01_RawData/ScalingValTable.csv")


# Calculate travel time -----
# there's a travel time for each segment using the upstream Q
# I don't average because you have to know the travel time to know the downstream Q
  # units: Q = m3/m; slope = m/m; ReachLg = m
    
    TTfunDu <- function(Q,slope,n, ReachLg){
      V_p <- slope^(3/8) * Q^(1/4) * n^(-3/4)
      tt <- ReachLg/V_p
    }

## West Ck ----
# 3 reaches: West Ck to STF to Maumee @ Defiance to Maumee @ Waterville
  wqWC2 <- wqWC %>% 
    filter(dateTime < as.POSIXct("2019-07-01 00:00:00", format = "%Y-%m-%d %H:%M:%S")) %>% 
    # travel time from smp site to next ds gaging station
    # units: minutes
    mutate(tt_min.l1 = TTfunDu(Q = Qm3m, 
                              segInfo[segInfo$Gauge_start == "WC",]$SlopeMm, # slope
                              0.037/60, 
                              segInfo[segInfo$Gauge_start == "WC",]$SegLgM)) %>% 
    mutate(dateTimeAtl2 = round_date(dateTime + (tt_min.l1*60), unit = "15 minutes")) %>% 
    left_join(wqSTF %>% 
                select(dateTime, Qm3m), by = c("dateTimeAtl2" = "dateTime"), suffix = c("_WC", "_STF")) %>% 
    # some missing time points
    mutate(Qm3m_STF = na.approx(Qm3m_STF)) %>%
    # travel time from gaging station 2 to gaging station 3
    mutate(tt_min.l2 = TTfunDu(Qm3m_STF, 
                              segInfo[segInfo$Gauge_start == "STF",]$SlopeMm,  
                              0.037/60, 
                              segInfo[segInfo$Gauge_start == "STF",]$SegLgM)) %>% 
    mutate(dateTimeAtl3 = round_date(dateTime + (tt_min.l1*60) + (tt_min.l2*60), unit = "15 minutes")) %>% 
    left_join(qMrDef, by = c("dateTimeAtl3" = "dateTime")) %>% 
    # some missing time points
    # travel time from gaging station 3 to gaging station 4
    mutate(tt_min.l3 = TTfunDu(Qm3m_MrDef, 
                              segInfo[segInfo$Gauge_start == "MMDF",]$SlopeMm, 
                              0.037/60, 
                              segInfo[segInfo$Gauge_start == "MMDF",]$SegLgM),
           tt_min.tot = tt_min.l1 + tt_min.l2 + tt_min.l3,
           segLg_M = segInfo[segInfo$Gauge_start == "WC",]$SegLgM +
             segInfo[segInfo$Gauge_start == "STF",]$SegLgM + 
             segInfo[segInfo$Gauge_start == "MMDF",]$SegLgM) %>% 
    select(dateTime:gTarPerFlow, tt_min.tot, segLg_M) %>% 
    rename(Qm3m = "Qm3m_WC")
    

## STF ----
# 2 reaches: STF to Maumee @ Defiance to Maumee @ Waterville
  wqSTF2 <- wqSTF %>% 
    filter(dateTime < as.POSIXct("2019-07-01 00:00:00", format = "%Y-%m-%d %H:%M:%S")) %>% 
    # travel time from smp site to next ds gaging station
    mutate(tt_min.l1 = TTfunDu(Q = Qm3m, 
                               segInfo[segInfo$Gauge_start == "STF",]$SlopeMm, # slope
                               0.037/60, 
                               segInfo[segInfo$Gauge_start == "STF",]$SegLgM)) %>% # units: minutes
    mutate(dateTimeAtl2 = round_date(dateTime + (tt_min.l1*60), unit = "15 minutes")) %>% 
    left_join(qMrDef, by = c("dateTimeAtl2" = "dateTime")) %>% 
    # travel time from gaging station 2 to gaging station 3
    mutate(tt_min.l2 = TTfunDu(Qm3m_MrDef, 
                               segInfo[segInfo$Gauge_start == "MMDF",]$SlopeMm,  
                               0.037/60, 
                               segInfo[segInfo$Gauge_start == "MMDF",]$SegLgM),
           tt_min.tot = tt_min.l1 + tt_min.l2,
           segLg_M = segInfo[segInfo$Gauge_start == "STF",]$SegLgM + 
             segInfo[segInfo$Gauge_start == "MMDF",]$SegLgM) %>% 
    select(dateTime:gTarPerFlow, tt_min.tot, segLg_M)


## UTLC ----
# 2 reaches: UTLC to Maumee @ Defiance to Maumee @ Waterville
  wqUTLC2 <- wqUTLC %>% 
    filter(dateTime < as.POSIXct("2019-07-01 00:00:00", format = "%Y-%m-%d %H:%M:%S")) %>% 
    # travel time from smp site to next ds gaging station
    mutate(tt_min.l1 = TTfunDu(Q = Qm3m, 
                               segInfo[segInfo$Gauge_start == "UTLC",]$SlopeMm, # slope
                               0.037/60, 
                               segInfo[segInfo$Gauge_start == "UTLC",]$SegLgM)) %>% # units: minutes
    mutate(dateTimeAtl2 = round_date(dateTime + (tt_min.l1*60), unit = "15 minutes")) %>% 
    left_join(qMrDef, by = c("dateTimeAtl2" = "dateTime")) %>% 
    # travel time from gaging station 2 to gaging station 3
    mutate(tt_min.l2 = TTfunDu(Qm3m_MrDef, 
                               segInfo[segInfo$Gauge_start == "MMDF",]$SlopeMm,  
                               0.037/60, 
                               segInfo[segInfo$Gauge_start == "MMDF",]$SegLgM),
           tt_min.tot = tt_min.l1 + tt_min.l2,
           segLg_M = segInfo[segInfo$Gauge_start == "UTLC",]$SegLgM + 
             segInfo[segInfo$Gauge_start == "MMDF",]$SegLgM) %>% 
  select(dateTime:gTarPerFlow, tt_min.tot, segLg_M)

## save WQ files ----
# These are needed to redo this to evaluate various assumptions about the PO4/DRP ratio
# since these feed right into the bootstrap
write.csv(wqUTLC2, file.path(here::here("04a_generatedDataOnGit"),"04_WQandTT_UTLC.csv"))
write.csv(wqSTF2, file.path(here::here("04a_generatedDataOnGit"),"04_WQandTT_STF.csv"))
write.csv(wqWC2, file.path(here::here("04a_generatedDataOnGit"),"04_WQandTT_WC.csv"))

# Scale and bootstrap Tribs ----
  ## Scaling function ----
  ScalingFun <- function(WQdat, Sms_gPgDMmin.Med, Scap_gPgDM, StreamEPC, TimeWin){
    WQdat2 <- WQdat %>% 
      mutate(
        # potential ms sorption rate gP/gDM for the entire tt - needs MINS
        Sms_gPgDMtt.P = Sms_gPgDMmin.Med * tt_min.tot, #using tt_du here seems most reliable
        # final ms sorption rate gP/gDM for entire tt
        Sms_gPgDMtt.F = ifelse(Sms_gPgDMtt.P > Scap_gPgDM, Scap_gPgDM, Sms_gPgDMtt.P),
        # what percent of capacity?
        Sms_porCap = Sms_gPgDMtt.P/Scap_gPgDM,
        # potential volumetric sorption rate gP/m3/tt (w constraints on capacity)
        Svol_gPm3TT.P = Sms_gPgDMtt.F * SSgDMm3,
        # difference between DRP and EPC gP/m3
        DifDRP.EPC = ifelse((DRPgPm3 - StreamEPC)>0, DRPgPm3 - StreamEPC,0),
        # final volumetric sorption rate gP/m3/tt
        Svol_gPm3TT.F = ifelse(Svol_gPm3TT.P < DifDRP.EPC, Svol_gPm3TT.P, DifDRP.EPC),
        # potential volumetric sorption rate (w/o constraints on capacity or EPC)
        Svol_gPm3TT.P2 = Sms_gPgDMtt.P * SSgDMm3,
        # how far did the particle travel while sorbing
        # bit simplistic because it assumes velocity is same across reaches
        SorbDistM = Svol_gPm3TT.F/Svol_gPm3TT.P2 * segLg_M,
        # how much time did it take to saturate
        # again simplistic because it assumes velocity is same across reaches
        SorbTimeMin = Svol_gPm3TT.F/Svol_gPm3TT.P2 * tt_min.tot) %>% 
      # NOW THE SCALING
      # DRP moving DS during between samples gP/window
      mutate(DRPloadUS.gPwin = DRPgPm3 * Qm3m * TimeWin,
             # SS moving DS during window g DM/window
             SSloadUS.gDMwin = SSgDMm3 * Qm3m * TimeWin,
             # Vol sorption for all water in window gDM/window
             Svol_gPwindow = Svol_gPm3TT.F * Qm3m * TimeWin,
             # DRP load at DS site without sorption; gP/window
             DRPloadDS.gPwin.wS = DRPloadUS.gPwin + Svol_gPwindow,
             # portion of DRP sorbed
             porDRPloadSorbed = Svol_gPwindow/DRPloadUS.gPwin,
             # P sorbed/gSS in all water passing by station in a window
             gPsorb_gSS = Svol_gPwindow/SSloadUS.gDMwin,
             # putting parameters in final dataframe
             Sms_gPgDMmin.Med = Sms_gPgDMmin.Med,
             Scap_gPgDM = Scap_gPgDM,
             StreamEPC = StreamEPC)
    
    WQdat2
  }



## Scaling bootstrap function ----
ScalingBootFun <- function(
         SorpDatHF, 
         BootNum,
         WQdat, 
         TimeWin){

    # empty dataframe
  streamWQ_ibs <- as.data.frame(matrix(nrow = 1, ncol = 26))
  names(streamWQ_ibs) <- c("dateTime", "Qm3m", "SSgDMm3", "DRPgPm3", "gTarPerFlow", "tt_min.tot", "segLg_M", "Sms_gPgDMtt.P", "Sms_gPgDMtt.F",
                           "Sms_porCap", "Svol_gPm3TT.P", "DifDRP.EPC", "Svol_gPm3TT.F", "Svol_gPm3TT.P2", "SorbDistM", "SorbTimeMin", "DRPloadUS.gPwin" ,  
                           "SSloadUS.gDMwin", "Svol_gPwindow", "DRPloadDS.gPwin.wS", "porDRPloadSorbed", "gPsorb_gSS", "Sms_gPgDMmin.Med", 
                           "Scap_gPgDM", "StreamEPC", "bootN")
  
  # bootstrapping loop
  for(i in 1:BootNum) {
    # number of sorption measurements
    SorpSmpN <- seq(1,length(SorpDatHF$Sms_gPgDMmin))
    # random sample of mass specific sorption measurements with length of water quality data; units = gP/gDM/min
    Sms_gPgDMmin.Med_i = SorpDatHF$Sms_gPgDMmin[sample(SorpSmpN, size = dim(WQdat)[1], replace = TRUE)]
    # random sample of sorption capacity with length of water quality data; units = gP/gDM
    Scap_gPgDM_i = SorpDatHF$Scap_gPgDM[sample(SorpSmpN, size = dim(WQdat)[1], replace = TRUE)] 
    # random sample of EPC with length of water quality data; units = gP/m3
    StreamEPC_i = SorpDatHF$EPC_gPm3[sample(SorpSmpN, size = dim(WQdat)[1], replace = TRUE)]
    streamWQ2legnth <- dim(WQdat)[1]
    # function calculates travel time using Du equation
    # estimates volumetric sorption rate (gP/m3/tt) of entire travel time out of reach
    # Then, estimates sorption for the window
    streamWQ_i <- ScalingFun(WQdat, Sms_gPgDMmin.Med_i, Scap_gPgDM_i, StreamEPC_i, TimeWin) %>% 
      mutate(bootN = i)
    streamWQ_ibs <- rbind(streamWQ_ibs,streamWQ_i)
  }
  streamWQ_ibs
}

# Trib bootstratps ----
# each of these takes 10-20 min
## STF ----
    TribScalSTF <- ScalingBootFun(SorpDatHF = SorpSTF_Hf, 
                                    BootNum = 500,
                                    WQdat = wqSTF2, 
                                    TimeWin = 15)

## WC ----
    TribScalWC <- ScalingBootFun(SorpDatHF = SorpWC_Hf, 
                                    BootNum = 500,
                                    WQdat = wqWC2 , 
                                    TimeWin = 15)
  
  ## UTLC ----
    TribScalUTLC <- ScalingBootFun(SorpDatHF = SorpUTLC_Hf, 
                                    BootNum = 500,
                                    WQdat = wqUTLC2 , 
                                    TimeWin = 15)
  
## Save trib bootstraps ----
# takes a while
write.csv(TribScalSTF, file.path(here::here("04a_generatedDataTooBigForGit"), "04_TribRawBootstrapResults_STF.csv"))
write.csv(TribScalWC, file.path(here::here("04a_generatedDataTooBigForGit"), "04_TribRawBootstrapResults_WC.csv"))
write.csv(TribScalUTLC, file.path(here::here("04a_generatedDataTooBigForGit"), "04_TribRawBootstrapResults_UTLC.csv"))

## Combine sorp estimates for Maumee ----
# Need a big vector of g P sorbed/ g SS
# This is every bootstraped estimate of gPsorbed/gSS - maximizing variation
# but restricting to high flow and to Mar-Jun


gPsrbGdmData <- rbind(TribScalSTF %>% 
                        mutate(stream = "STF"), 
                      TribScalWC %>% 
                        mutate(stream = "WC"), 
                      TribScalUTLC %>% 
                        mutate(stream = "UTLC")) %>%   
                  filter(gTarPerFlow == "Gtarget") %>% 
                  select(dateTime, gPsorb_gSS) %>% 
                  mutate(dateTime = as.POSIXct(dateTime, origin = "1970-01-01 00:00.00 UTC")) %>% 
                  filter(dateTime >= StartStumpf & dateTime <= EndStumpf)

# distribution of P sorption/gSS
# This is how much P is sorbed between the trib where this was measured and waterville.
# sorption saturated in all tribs.
hist(gPsrbGdmData$gPsorb_gSS)

# Scale & bootstrap Maumee ----
# took out TP from datasets because I didn't use it.
# 1 mg/L = 1 g/m3 so units on the concentrations work here

## Maumee bootstrap function ----
MaumFun <- function(WQDat, gPsorbedgDMe){
  WQDat2 <- WQDat %>% 
    select(Date, SmpTimeWindowDay, Qm3day:gSRPday, SS_gm3:SRP_gm3, HighFlow) %>% #TP_mgL, 
    # estimate P sorbed
    mutate(gPsorbedgDM = gPsorbedgDMe,
           # this is potential, which can exceed DRP if not bounded
           gPsorbWindowP = gPsorbedgDM * gSSday,
           # bound sorption to available P
           # conservative since we argue that DRP upstream was higher
           # NOT USING THIS HERE
           gPsorbWindow = ifelse(gPsorbWindowP > gSRPday, gSRPday, gPsorbWindowP),
           # estimate DRP load - observed + sorbed)
           gDRPwindowWOsorpP = gSRPday + gPsorbWindowP,
           gDRPwindowWOsorp = gSRPday + gPsorbWindow)
  
  WQDat2
}

## Maumee bootstrap ----
# number of draws
BootNum <- 500

# empty dataframe
streamWQ_MW <- as.data.frame(matrix(nrow = 1, ncol = 13)) %>% 
  mutate(bootN = as.numeric("NA"))

names(streamWQ_MW) <- c("Date", "SmpTimeWindowDay", "Qm3day", "gSSday", "gSRPday",
                         "SS_gm3", "SRP_gm3", "HighFlow", "gPsorbedgDM", "gPsorbWindowP", "gPsorbWindow", "gDRPwindowWOsorpP", "gDRPwindowWOsorp", "bootN")


# Bootstrap maumee data
  for(i in 1:BootNum) {
    # i = 1
    SorpSmpN <- seq(1,length(gPsrbGdmData$gPsorb_gSS))
    gPsorbedgDMe_i = gPsrbGdmData$gPsorb_gSS[sample(SorpSmpN, size = dim(wqMaum)[1], replace = TRUE)]
    streamWQ_i <-  MaumFun(WQDat = wqMaum,
                           gPsorbedgDMe = gPsorbedgDMe_i) %>%
      mutate(bootN = i)
    streamWQ_MW <- rbind(streamWQ_MW, streamWQ_i)
  }
  
  streamWQ_MW2 <- streamWQ_MW[-1,]

## Export Maumee scaled dat ----
# write.csv(streamWQ_MW, file.path(here::here("04a_generatedDataTooBigForGit"), "04_RawBootstrapResults_Maumee.csv"))


# save/load ----
# save.image(file.path(here::here("03_Rdata"),"06c_ScalingSorption2TribMaumee_Rdata"))
# load(file.path(here::here("03_Rdata"),"06c_ScalingSorption2TribMaumee_Rdata"))















